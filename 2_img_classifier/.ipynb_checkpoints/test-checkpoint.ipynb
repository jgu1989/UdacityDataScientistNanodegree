{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10...  Loss: 4.5743\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from load import load_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def do_deep_learning(model, trainloader, epochs, print_every, criterion, optimizer, device='cpu'):\n",
    "    steps = 0\n",
    "\n",
    "    # change to cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for ii, (inputs, labels) in enumerate(trainloader):\n",
    "            print('what?')\n",
    "            steps += 1\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward passes\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if steps % print_every == 0:\n",
    "                print(\"Epoch: {}/{}... \".format(e + 1, epochs),\n",
    "                      \"Loss: {:.4f}\".format(running_loss / print_every))\n",
    "\n",
    "                running_loss = 0\n",
    "            return model\n",
    "\n",
    "def check_accuracy_on_test(model, testloader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "def save_checkpoint(model, save_dir):\n",
    "    model.class_to_idx = dataloaders['train'].dataset.class_to_idx\n",
    "    checkpoint = {'input_size': [3, 224, 224],\n",
    "                  'output_size': 102,\n",
    "                  'state_dict': model.state_dict(),\n",
    "                  'class_to_idx': model.class_to_idx}\n",
    "    torch.save(checkpoint, save_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Train image classifier')\n",
    "# parser.add_argument('--save_dir', type=str,  required=True, help='Directory to save checkpoint')\n",
    "# parser.add_argument('--arch', type=str, required=True, help='Architecture')\n",
    "# parser.add_argument('--learning_rate', type=float, required=True, help='Learning rate')\n",
    "# parser.add_argument('--hidden_units')\n",
    "# parser.add_argument('--epochs', type=int,  required=True, help='Number of epochs')\n",
    "# parser.add_mutually_exclusive_group().add_argument('--gpu', action='store_true', help='Use GPU')\n",
    "#\n",
    "# args = parser.parse_args()\n",
    "\n",
    "dataloaders = load_data('flowers')\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(1024, 500)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(500, 102)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "model = do_deep_learning(model, dataloaders['train'], 10, 1, criterion, optimizer, 'cpu')\n",
    "# check_accuracy_on_test(model, dataloaders['test'],'cpu')\n",
    "\n",
    "save_dir = 'checkpoint.pth'\n",
    "save_checkpoint(model, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
